<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>论文笔记 | Explainfuture's Blog</title><meta name="author" content="Explainfuture"><meta name="copyright" content="Explainfuture"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="COFFEEc:cross-layer optimization for fast and efficient executions of the SK algorithm on HPC systems with clusters of compute nodes在有计算节点集群的HPC系统上快速高效执行SK算法。算法中：行、列都可以重新缩放，列缩放相较行缩放极其缓慢。在多节点上的性能比单节点提升">
<meta property="og:type" content="article">
<meta property="og:title" content="论文笔记">
<meta property="og:url" content="https://www.explainsf.com/2025/03/28/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/index.html">
<meta property="og:site_name" content="Explainfuture&#39;s Blog">
<meta property="og:description" content="COFFEEc:cross-layer optimization for fast and efficient executions of the SK algorithm on HPC systems with clusters of compute nodes在有计算节点集群的HPC系统上快速高效执行SK算法。算法中：行、列都可以重新缩放，列缩放相较行缩放极其缓慢。在多节点上的性能比单节点提升">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://www.explainsf.com/image/head.jpeg">
<meta property="article:published_time" content="2025-03-28T10:51:45.000Z">
<meta property="article:modified_time" content="2025-04-08T06:05:18.126Z">
<meta property="article:author" content="Explainfuture">
<meta property="article:tag" content="CS">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://www.explainsf.com/image/head.jpeg"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "论文笔记",
  "url": "https://www.explainsf.com/2025/03/28/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/",
  "image": "https://www.explainsf.com/image/head.jpeg",
  "datePublished": "2025-03-28T10:51:45.000Z",
  "dateModified": "2025-04-08T06:05:18.126Z",
  "author": [
    {
      "@type": "Person",
      "name": "Explainfuture",
      "url": "https://www.explainsf.com/"
    }
  ]
}</script><link rel="shortcut icon" href="/image/favicon.ico"><link rel="canonical" href="https://www.explainsf.com/2025/03/28/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//fonts.googleapis.com" crossorigin=""/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web&amp;display=swap" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"top_n_per_article":-1,"unescape":true,"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":true,"highlightMacStyle":true},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: true,
    post: true
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: {"chs_to_cht":"已切换为繁体中文","cht_to_chs":"已切换为简体中文","day_to_night":"已切换为深色模式","night_to_day":"已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"top-right"},
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: true,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '论文笔记',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 7.3.0"></head><body><div id="web_bg" style="background-image: url(https://picbedex.oss-cn-shenzhen.aliyuncs.com/20250311153314058.jpg);"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/image/head.jpeg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">31</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">4</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-heartbeat"></i><span> 清单</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://picbedex.oss-cn-shenzhen.aliyuncs.com/20250311153417995.jpg);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">Explainfuture's Blog</span></a><a class="nav-page-title" href="/"><span class="site-name">论文笔记</span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-heartbeat"></i><span> 清单</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">论文笔记</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-03-28T10:51:45.000Z" title="发表于 2025-03-28 18:51:45">2025-03-28</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-04-08T06:05:18.126Z" title="更新于 2025-04-08 14:05:18">2025-04-08</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">总字数:</span><span class="word-count">4.6k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>14分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h1 id="COFFEE"><a href="#COFFEE" class="headerlink" title="COFFEE"></a>COFFEE</h1><p>c:cross-layer optimization for fast and efficient executions of the SK algorithm on HPC systems with clusters of compute nodes<br>在有计算节点集群的HPC系统上快速高效执行SK算法。<br><strong>算法中：行、列都可以重新缩放</strong>，<strong>列缩放相较行缩放极其缓慢</strong>。<br>在多节点上的性能比单节点提升最高7.5倍，平均2倍；与天河一号的MPI Allreduce算法比，最高2.9，平均1.6.<br>SK算法：a simple but very useful iterative method to approach the double stochastic matrix of Sinkhorn’s theorem by alternately rescaling all rows and all columns of the given matrix.<br>对矩阵进行缩放列。</p>
<p>现存的SK算法大多用去搞强化学习了（应用层），或者去加速收敛，很少有研究从计算机系统架构的角度考虑改进算法，特别是高性能计算（HPC）系统。HPC有他自己独特的计算、存储以及交流能力，看看是否能发挥全部潜力。SK算法在四个代表性应用的时间占比都超过一半（BALS的卷积也这样）所以就去优化。</p>
<p><strong>这篇论文用MPI，通过多核、多节点集群加速SK算法。</strong><br>先分析经典算法在天河1上。<br>列缩放的时间远超行缩放，原因是<strong>通过列缩放进行的内存访问是高度非连续的，这导致了较高的缓存未命中率。</strong><br>解决方法：<strong>探险重新设计列缩放以及信息阻塞</strong>去减少缓存未命中；设计微核并且重新设计指令去<strong>增加并行性</strong></p>
<p>优化思想：通用矩阵乘法、分层<br>分层的思想在MPI Allreduce算法（MPI_Allreduce 是 MPI（消息传递接口）中的一个函数，用于在所有进程之间<strong>进行归约操作并广播结果。</strong>）的相关优化中非常常见。</p>
<p>选择SALaR（？）作为基准去研究。发现：实现Allreduce可以与SK算法的其他任务进行overlap（重叠）进一部提高性能   </p>
<h2 id="本篇文章的主要contribution"><a href="#本篇文章的主要contribution" class="headerlink" title="本篇文章的主要contribution"></a>本篇文章的主要contribution</h2><ul>
<li>我们分析了 SK 算法在 HPC 集群上的执行行为，并观察到两个主要的性能挑战。首先是其列重新缩放表现出高度非连续的内存访问模式，这导致非常高的缓存未命中率，从而大大降低了整体性能。第二，即使采用 Foster 的方法设计，列重新缩放也会严重限制并行性</li>
<li>我们提出了 COFFEE，这是一种新颖的方法，它实现了多级优化设计，以优化 HPC 系统中大规模 SK 算法的处理（第 IV 节）。我们通过增强 MPI Allreduce 来提高并行效率，采用有效的领导者-工作者机制，尽可能重叠节点间(intra-node)通信、节点内通信和节点内计算</li>
<li>我们在天河一号超级计算机上评估了 COFFEE 的原型实现，证明了其与 SOTA 解决方案相比具有显著的性能优势（第六节）。我们的实验结果表明，COFFEE 分别在单节点和多节点环境中带来了高达 7.5 倍和 2.9 倍的性能提升。</li>
</ul>
<h2 id="SK算法"><a href="#SK算法" class="headerlink" title="SK算法"></a>SK算法</h2><p>双随机矩阵,sk算法就是在行列都归一化后，每行元素相加都为1，每列元素相加也都为1<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbedex.oss-cn-shenzhen.aliyuncs.com/20250328202355119.png"></p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sinkhorn</span>(<span class="params">A, max_iter=<span class="number">1000</span>, tol=<span class="number">1e-6</span></span>):</span><br><span class="line">    A = np.array(A, dtype=np.float64)</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(max_iter):</span><br><span class="line">        A_prev = A.copy()</span><br><span class="line">        A /= A.<span class="built_in">sum</span>(axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>)  <span class="comment"># 行归一化</span></span><br><span class="line">        A /= A.<span class="built_in">sum</span>(axis=<span class="number">0</span>, keepdims=<span class="literal">True</span>)  <span class="comment"># 列归一化</span></span><br><span class="line">        <span class="keyword">if</span> np.allclose(A, A_prev, atol=tol):</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">return</span> A</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例</span></span><br><span class="line">A = np.array([[<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>], [<span class="number">3</span>, <span class="number">4</span>,<span class="number">2</span>],[<span class="number">7</span>,<span class="number">8</span>,<span class="number">5</span>]])</span><br><span class="line">B = sinkhorn(A)</span><br><span class="line"><span class="built_in">print</span>(B)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Row sums:&quot;</span>, B.<span class="built_in">sum</span>(axis=<span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Col sums:&quot;</span>, B.<span class="built_in">sum</span>(axis=<span class="number">0</span>))</span><br></pre></td></tr></table></figure>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbedex.oss-cn-shenzhen.aliyuncs.com/20250328203003067.png"></p>
<p>选SK算法而不是和其他算法有两重原因：</p>
<ul>
<li>现在主流的线性代数库（如 BLAS、NumPy、PyTorch 等）在进行矩阵乘法时，底层通常使用的是最基础的“三重循环”实现方式，而不是像 Strassen 或 Coppersmith-Winograd 这样的快速乘法算法。就像基本的矩阵乘法实现一样，最原始的 Sinkhorn-Knopp（SK）算法也<strong>更容易从计算机系统架构的角度进行优化</strong>。</li>
<li>现有的 SK 算法研究主要集中于通过<strong>减少矩阵缩放迭代次数</strong>来加快收敛速度​​，但我们的目标是<strong>减少每次迭代的时间</strong>。</li>
</ul>
<p>我们不再去限制每一行&#x2F;每一列的和接近1，而是去最后计算的时候让行&#x2F;列和为1，在计算结果之前不需要让它接近1。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbedex.oss-cn-shenzhen.aliyuncs.com/20250328205256791.png"></p>
<p>Intel团队用Python。为了在超算上运行，我们选C实现，是他们SOTApython的重写，有循环展开和数据并行优化，并且性能不逊于他们。</p>
<p>串行处理行列缩放,明显看到列用了十几倍的时间。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbedex.oss-cn-shenzhen.aliyuncs.com/20250328212937491.png"></p>
<h2 id="介绍典型的并行算法"><a href="#介绍典型的并行算法" class="headerlink" title="介绍典型的并行算法"></a>介绍典型的并行算法</h2><p>关键点：如何分割数据和任务让交流<strong>少一些</strong>，让计算任务更<strong>稳定</strong>。<br>处理方法：把矩阵按行划分成多个子矩阵，每个处理器只负责其中一些行，这样在<strong>行归一化</strong>的时候每个处理器只需要处理自己的行，不需要通信；最后让通信发生在<strong>列归一化</strong>阶段，这部分可以统一优化。这样目的是<strong>把本地能算的留在本地，只在必要时跨节点通信</strong>。<br>算法执行被拆成四步：</p>
<ul>
<li>每个进程独立地对自己那一块行子矩阵进行行归一化（和算法1的第1–10行一样），不需要通信；</li>
<li>每个进程计算自己那部分子矩阵的列和；</li>
<li>调用 MPI_Allreduce 汇总所有进程的列和，得到全矩阵每列的总和；</li>
<li>每个进程根据上一步得到的列缩放因子，独立地对自己那块子矩阵做列归一化。<br>这样做能最大限度减少通信，仅在列缩放因子计算这一步使用 MPI，有利于并行效率。</li>
</ul>
<h2 id="图片示例"><a href="#图片示例" class="headerlink" title="图片示例"></a>图片示例</h2><p>在计算并行效率的时候，列缩放时处理器数为16的效率也骤降？<br>原因：<strong>行缩放</strong>的时候不需要进行通信，所有的处理器被平衡地加载；但到<strong>列缩放</strong>的时候处理器在等数据。<br><em>The reason is that the row rescaling is communication free and all the processors are load balanced. While for the column rescaling, the Allreduce used to find the column sum performs a lot of inter-node and intra-node communication, so that some processors are in the process of waiting for data</em> </p>
<h2 id="Motivation-of-COFFEE"><a href="#Motivation-of-COFFEE" class="headerlink" title="Motivation of COFFEE"></a>Motivation of COFFEE</h2><p>我们看到了在并行处理行缩放时候节点内的通信花费了太多时间，大大降低效率；因此我们想利用节点的不同通信特点，然后提升效率。</p>
<p>算法设计-微核设计-MPI优化</p>
<h2 id="CPU-ORIENTED-OPTIMIZATION"><a href="#CPU-ORIENTED-OPTIMIZATION" class="headerlink" title="CPU-ORIENTED OPTIMIZATION"></a>CPU-ORIENTED OPTIMIZATION</h2><p>列重排算法设计（Algorithm1和2的对比）</p>
<h2 id="Micro-kernel-redesign"><a href="#Micro-kernel-redesign" class="headerlink" title="Micro-kernel redesign"></a>Micro-kernel redesign</h2><p>采用SIMD：SIMD（Single Instruction, Multiple Data，单指令多数据流）是一种并行计算技术，它让一个指令同时处理多个数据。常用于图像处理、音频处理、科学计算等场景，加速处理速度，提升性能。<br>采用AVX2指令集：AVX2（Advanced Vector Extensions 2）是Intel推出的SIMD指令集扩展，属于x86架构的一部分。它在AVX的基础上增强了整数运算能力，支持256位宽的YMM寄存器，可以并行处理更多数据，广泛用于图像处理、机器学习等高性能计算中。<br>修改汇编指令</p>
<h2 id="MPI-optimization"><a href="#MPI-optimization" class="headerlink" title="MPI optimization"></a>MPI optimization</h2><h3 id="节点内Reduce算法优化"><a href="#节点内Reduce算法优化" class="headerlink" title="节点内Reduce算法优化"></a>节点内Reduce算法优化</h3><p>二叉树效率低是因为每个处理器开销不同，尤其在根节点，其他处理器都空闲（idle），<strong>加载不均</strong>。<br>为了解决这种严重的负载不均衡问题，我们重新设计了SK算法的Reduce实现，将本地和数组分成几部分。在节点内Reduce之后，每个worker保留本地最终和的一部分并以非阻塞方式将其发送给leader。我们的节点内Reduce实现基于MPI标准原语MPI_Send和MPI_Recv，与MPICH库中Reduce的实现一致。我们没有使用打包技术，因为要传递的数据几乎是连续的，打包带来的额外开销超过了使用它带来的性能提升。</p>
<h3 id="节点间AllReduce算法优化"><a href="#节点间AllReduce算法优化" class="headerlink" title="节点间AllReduce算法优化"></a>节点间AllReduce算法优化</h3><p>我们使用最流行的 Ring 算法实现 Allreduce，以生成列重新缩放的全局最终总和。Ring Allreduce 的一个缺点是它没有考虑节点的层次结构。一般来说，节点之间的带宽远低于节点内的带宽。因此，最近提出了分层 Ring Allreduce。<br>图 7 显示了我们基于分层环的优化。<br>主要思想是重叠节点内 Reduce 和节点间 Allreduce 的时间。我们将本地和数组分成几个数据块。如前所述，对数据块进行 allreduce 有三个连续步骤。首先，工作者对本地和的块执行节点内 Reduce，并将本地最终总和发送给领导者（图 7 中时间 1 的红色箭头）。接下来，领导者对全局最终总和执行节点间 Allreduce（图 7 中时间 2 的红色箭头）。最后，领导者将全局最终总和广播给其工作者（图 7 中时间 3 的红色箭头）。发现不同数据块的顺序步骤可以重叠。例如，图 7 中的时间 2 表示第 i 个数据块的节点间 Allreduce（红色箭头）和第 (i + 1) 个数据块的节点内 Reduce（黑色箭头）可以同时处理。因此，我们在为 SK 算法实现 Allreduce 时将管道的思想结合到分层环中。</p>
<h3 id="重叠通信和计算优化"><a href="#重叠通信和计算优化" class="headerlink" title="重叠通信和计算优化"></a>重叠通信和计算优化</h3><p>当领导者执行 Allreduce 时，工作者必须停滞。我们利用这段停滞时间让工作者修改节点内的矩阵。在我们对 SK 算法的优化 Allreduce 设计中，矩阵修改的计算被添加到流水线中。<br><strong>同时完成 Allreduce 的通信任务和修改子矩阵的计算任务</strong></p>
<h2 id="experiment-evaluation"><a href="#experiment-evaluation" class="headerlink" title="experiment evaluation"></a>experiment evaluation</h2><h3 id="Experimental-Setup"><a href="#Experimental-Setup" class="headerlink" title="Experimental Setup"></a>Experimental Setup</h3><p>为了评估 COFFEE 的有效性，我们将其两个版本进行比较，即面向 CPU 的优化（第 IV 节），表示为 COFFEE-CPU，以及面向 MPI 的优化（第 V 节），表示为 COFFEE-MPI，与 SK 算法的两个现有实现进行比较，一个使用 Ring Allreduce 算法（MPICH-Ring），另一个在 MPICH 环境中使用 SALaR（MPICH-SALaR）<br>高密度矩阵（非零元素占 95%）、中等密度矩阵（非零元素占 50%）、稀疏矩阵（非零元素占 5%）<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbedex.oss-cn-shenzhen.aliyuncs.com/20250330172903583.png"><br>只去算非零矩阵。</p>
<h3 id="CPU-Oriented-Optimization"><a href="#CPU-Oriented-Optimization" class="headerlink" title="CPU-Oriented Optimization"></a>CPU-Oriented Optimization</h3><p>在AMD平台上使用GCC编译器运行的SK算法通过我们的优化获得了最大的改进。在ARM平台上使用Clang编译器，SK算法的典型实现的性能在所有平台上都是最好的，但我们的优化在M &#x3D; N &#x3D; 16,000时仍实现了3.3倍的加速比。</p>
<h3 id="MPI-Oriented-Optimization"><a href="#MPI-Oriented-Optimization" class="headerlink" title="MPI-Oriented Optimization"></a>MPI-Oriented Optimization</h3><h2 id="conclusion-and-further-work"><a href="#conclusion-and-further-work" class="headerlink" title="conclusion and further work"></a>conclusion and further work</h2><p>SK算法在机器学习等领域的重要性日益凸显。本文提出并实现了一种针对SK算法实现的计算和通信的跨层优化设计，称为COFFEE。与大多数现有的通过减少缩放迭代次数来加快收敛速度​​的工作不同，COFFEE着重于通过缩短每次缩放迭代来加快收敛速度​​。我们对SK算法实现中影响性能的问题进行了深入研究。发现列缩放会导致较高的缓存未命中率和较低的并行效率。我们使用列缩放重新设计、数据分块和微内核设计等跨层优化来加速列缩放。我们还根据SK算法的特点优化了MPI Reduce和Allreduce，以提高并行效率。最后，我们在天河一号超级计算机上验证了COFFEE 的有效性。未来我们计划进一步探索和利用行缩放和列缩放之间的相关性。此外，我们计划结合GPU，充分利用异构并行计算架构，进一步提高 COFFEE 的性能。最后，我们计划研究 COFFEE 在 SK 算法稀疏矩阵上的性能，其中数据不是以数组格式存储的。</p>
<h1 id="HSMU-SpGEMM"><a href="#HSMU-SpGEMM" class="headerlink" title="HSMU-SpGEMM"></a>HSMU-SpGEMM</h1><p>High Shared Memory Utilization for Parallel Sparse General Matrix-Matrix Multiplication on Modern GPUs<br>在现代 GPU 上实现并行稀疏通用矩阵-矩阵乘法的高共享内存利用率(utilization)</p>
<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>传统的基于哈希的方法无法在减少哈希冲突和有效利用快速共享内存之间取得平衡，这严重损害了在 GPU 上执行 SpGEMM 的性能。设计了一种<strong>累加器</strong>，四个通用库在三种架构上面跑，**HSMU有显著的加速优势。</p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>Gustavson算法在GPU上用于实现快速并行稀疏矩阵乘法时有两个流程：<strong>符号阶段(symbolic stage)<strong>以及</strong>数值阶段(numeric stage)</strong> </p>
<ul>
<li>符号阶段的主要任务是去确定矩阵C中非零元素的数量(NNZ)，以便在数值计算的时候<strong>预先分配内存</strong></li>
<li>数值阶段在已分配的内存上<strong>进行实际的乘法和累加</strong>，是整个SpGEMM<strong>最耗时的部分</strong><br>高效的累加器设计对数值阶段的性能至关重要。<br>单纯<strong>增加</strong>哈希表的容量会降低GPU共享内存的利用率。<br>主流SpGEMM库的不足</li>
<li>Nsparse 虽利用最大 NNZ 设置哈希表长度以提高共享内存利用率，但哈希冲突严重，性能下降</li>
<li>spECK 通过分配 1.5× 空间减少冲突但造成约 34% 内存浪费</li>
<li>OpSparse 建议设为 2× 最大 NNZ，性能好但共享内存利用率仅达 50%<br><strong>HSMU-SpGEMM 通过为每个累加器内核维护一个按列排序的数组（长度为分配行的最大 NNZ）来避免哈希冲突，并针对小规模与大规模矩阵设计不同的符号阶段，从而在优化 GPU 共享内存利用率下的同时保持低冲突率，实现高性能 SpGEMM。</strong></li>
</ul>
<h2 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h2><p>Gustavson 算法具有天然的并行性，因为它可以独立计算矩阵 C 的每一行。在数值阶段，矩阵 A 中每个非零元素 𝑎𝑖𝑗会与矩阵 B 中对应行𝑏𝑗∗的非零元素相乘，生成大量中间结果，这些结果的列索引与 B 中元素的列索引一致。最终，通过累加器将这些中间结果累加到矩阵 C 的相应位置。累加器的具体设计将在下一小节介绍。<br>分为两种累加器：<strong>稠密型</strong>和<strong>稀疏型</strong></p>
<ul>
<li><p>稠密累加器使用稠密数组存储中间结果，通常由三个向量组成：一个存储实际数值，一个用于标记列索引是否插入，另一个记录列索引。这种方法在处理稠密行时效率高，但对稀疏行内存需求大、性能较差。</p>
</li>
<li><p>稀疏累加器则按累加方式分为三类：基于合并、ESC 和哈希的累加器。</p>
</li>
<li><p>基于合并的稀疏累加器在 RMerge和 bhSPARSE等库中实现。这些累加器执行多次迭代，每次迭代将一个 NZ(Non-zero) 元素垂直合并到最终的稀疏向量中。由于在合并过程中使用了大小相同的临时数组，因此基于合并的稀疏累加器对于密度变化较大的矩阵表现出<strong>较低的内存利用率</strong>。</p>
</li>
<li><p>ESC 方法在处理生成大量中间产品的矩阵时存在不足。由于存储和分类大量中间产品会产生大量的空间开销和时间成本，因此效率低下。</p>
</li>
</ul>
<h2 id="Shared-Memory"><a href="#Shared-Memory" class="headerlink" title="Shared Memory"></a>Shared Memory</h2><p>除了寄存器文件之外，共享内存是 GPU 上最快的内存类型。共享内存的主要优点是它<strong>允许多个线程共享数据</strong>，这使得共享内存成为高效并行计算的关键 GPU 组件。共享内存可供单个线程块内的所有线程访问，并且可以将其视为可编程缓存或暂存器，在其中放置经常访问的数据。但是，GPU 上的共享内存容量有限。所以高性能共享内存是非常重要的对于现代GPU。</p>
<h1 id="MOTIVATION-OF-THE-WORK"><a href="#MOTIVATION-OF-THE-WORK" class="headerlink" title="MOTIVATION  OF THE WORK"></a>MOTIVATION  OF THE WORK</h1><h2 id="Principles-of-Hash-based-Accumulators"><a href="#Principles-of-Hash-based-Accumulators" class="headerlink" title="Principles of Hash-based Accumulators"></a>Principles of Hash-based Accumulators</h2><p>现有的哈希累加器要去平衡<strong>共享内存利用率</strong>和<strong>哈希碰撞率</strong></p>
<h2 id="Philosophy-of-HSMU-SpGEMM-Accumulator-Design"><a href="#Philosophy-of-HSMU-SpGEMM-Accumulator-Design" class="headerlink" title="Philosophy of HSMU-SpGEMM Accumulator Design"></a>Philosophy of HSMU-SpGEMM Accumulator Design</h2><ul>
<li>引入一个预排序列索引数组（sorted column indices array）表示 C 的非零列。使用 findInSorted(colIp, sortedColArray) 函数来定位每个中间乘积，直接查找中间乘积该落在哪个已知列上。<strong>完全消除哈希冲突，查找位置准确，无需哈希函数或冲突处理。</strong></li>
</ul>
<h1 id="HSMU-SPGEMM"><a href="#HSMU-SPGEMM" class="headerlink" title="HSMU-SPGEMM"></a>HSMU-SPGEMM</h1><h2 id="HSMU-SpGEMM-Accumulator-Design"><a href="#HSMU-SpGEMM-Accumulator-Design" class="headerlink" title="HSMU-SpGEMM Accumulator Design"></a>HSMU-SpGEMM Accumulator Design</h2><p>采用<strong>二分查找</strong>而不是哈希，<strong>可以低开销，高效率，并且很稳定</strong>。<br>有以下好处</p>
<ul>
<li>哈希法相对于二分查找法的最大优势在于，在哈希表中添加或删除项目的成本要低得多。然而，在 HSMU-SpGEMM 中，排序数组是在符号阶段预先确定的，因此我们的新累加器不需要在数字阶段更改排序数组。因此，二分查找法中维护排序结构的缺点不存在；</li>
<li>哈希表的一个缺点是，当发生碰撞时，它会影响其他哈希位置，并可能导致链式碰撞，导致哈希性能低下。而对于二分查找，其性能稳定，最坏情况为O（logN）。在这种情况下，二分查找优于哈希查找方法；</li>
<li>二分查找更适合于范围查询等复杂操作。在这种情况下，每个线程通过不断更新变量pos逐渐缩小共享col数组上的搜索范围，从而在一定程度上减少查找次数；尽管如此，对于密集和大数据，二分查找的最坏时间复杂度为O(logN)，而哈希表的理想时间为O(1)。时间复杂度的增加可能会在某些情况下降低我们的累加器设计的搜索性能。</li>
</ul>
<h2 id="Generate-the-Sorted-Ccol-Array"><a href="#Generate-the-Sorted-Ccol-Array" class="headerlink" title="Generate the Sorted Ccol Array"></a>Generate the Sorted Ccol Array</h2><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picbedex.oss-cn-shenzhen.aliyuncs.com/20250408135942607.png"><br>先生成maskB，对于每一行B，非零元素位置标记为1，其他为0。<br><strong>不太懂</strong>生成maskC的原理。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://www.explainsf.com">Explainfuture</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://www.explainsf.com/2025/03/28/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">https://www.explainsf.com/2025/03/28/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://www.explainsf.com" target="_blank">Explainfuture's Blog</a>！</span></div></div><div class="tag_share"><div class="post-share"><div class="social-share" data-image="/image/head.jpeg" data-sites="wechat,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2025/03/28/LearningHPC/" title="LearningHPC"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">LearningHPC</div></div><div class="info-2"><div class="info-item-1">Pytorch学习基础语法123from PIL import Imageimg_path = r&quot;D:\PythonProject2\hymenoptera_data\hymenoptera_data\train\ants\0013035.jpg&quot;img = Image.open(img_path) 这样就可以实现图片的打开。因为在python里面\t或者是\n是转义字符，直接加r表示这就是原始语义。 如果要读取一个文件夹里的许多图片，需要用到os库，然后使用列表的形式 123import osdir_path = r&quot;D:\PythonProject2\hymenoptera_data\hymenoptera_data\train\ants&quot;img_path_list = os.listdir(dir_path) 最后达到右边的效果 </div></div></div></a><a class="pagination-related" href="/2025/03/30/LeetCode/" title="LeetCode"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">LeetCode</div></div><div class="info-2"><div class="info-item-1">每日一题2025.3.30栈专题 1234567891011121314class Solution &#123;public:    string makeGood(string s) &#123;    string res;    for (char c : s) &#123;        if (!res.empty() &amp;&amp; abs(res.back() - c) == 32) &#123;            res.pop_back(); // 删除上一个相反大小写的字母        &#125; else &#123;            res.push_back(c);        &#125;    &#125;    return res;&#125;&#125;; 如果栈空，直接插入；如果栈非空，比较当前插入的字符和栈内的字符ascii码差值是否为32，32为大小写关系。 左右元素和的差值 123456789101112131415161718class Solution &#123;public:   ...</div></div></div></a></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/image/head.jpeg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Explainfuture</div><div class="author-info-description">这是一个计科学生终于开始学东西的记录网站</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">31</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">4</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/Explainfuture"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/Explainfuture" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:lcc@hnu.edu.cn" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#COFFEE"><span class="toc-number">1.</span> <span class="toc-text">COFFEE</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%AC%E7%AF%87%E6%96%87%E7%AB%A0%E7%9A%84%E4%B8%BB%E8%A6%81contribution"><span class="toc-number">1.1.</span> <span class="toc-text">本篇文章的主要contribution</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#SK%E7%AE%97%E6%B3%95"><span class="toc-number">1.2.</span> <span class="toc-text">SK算法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%8B%E7%BB%8D%E5%85%B8%E5%9E%8B%E7%9A%84%E5%B9%B6%E8%A1%8C%E7%AE%97%E6%B3%95"><span class="toc-number">1.3.</span> <span class="toc-text">介绍典型的并行算法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%BE%E7%89%87%E7%A4%BA%E4%BE%8B"><span class="toc-number">1.4.</span> <span class="toc-text">图片示例</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Motivation-of-COFFEE"><span class="toc-number">1.5.</span> <span class="toc-text">Motivation of COFFEE</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#CPU-ORIENTED-OPTIMIZATION"><span class="toc-number">1.6.</span> <span class="toc-text">CPU-ORIENTED OPTIMIZATION</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Micro-kernel-redesign"><span class="toc-number">1.7.</span> <span class="toc-text">Micro-kernel redesign</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#MPI-optimization"><span class="toc-number">1.8.</span> <span class="toc-text">MPI optimization</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%8A%82%E7%82%B9%E5%86%85Reduce%E7%AE%97%E6%B3%95%E4%BC%98%E5%8C%96"><span class="toc-number">1.8.1.</span> <span class="toc-text">节点内Reduce算法优化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%8A%82%E7%82%B9%E9%97%B4AllReduce%E7%AE%97%E6%B3%95%E4%BC%98%E5%8C%96"><span class="toc-number">1.8.2.</span> <span class="toc-text">节点间AllReduce算法优化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%87%8D%E5%8F%A0%E9%80%9A%E4%BF%A1%E5%92%8C%E8%AE%A1%E7%AE%97%E4%BC%98%E5%8C%96"><span class="toc-number">1.8.3.</span> <span class="toc-text">重叠通信和计算优化</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#experiment-evaluation"><span class="toc-number">1.9.</span> <span class="toc-text">experiment evaluation</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Experimental-Setup"><span class="toc-number">1.9.1.</span> <span class="toc-text">Experimental Setup</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#CPU-Oriented-Optimization"><span class="toc-number">1.9.2.</span> <span class="toc-text">CPU-Oriented Optimization</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#MPI-Oriented-Optimization"><span class="toc-number">1.9.3.</span> <span class="toc-text">MPI-Oriented Optimization</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#conclusion-and-further-work"><span class="toc-number">1.10.</span> <span class="toc-text">conclusion and further work</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#HSMU-SpGEMM"><span class="toc-number">2.</span> <span class="toc-text">HSMU-SpGEMM</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Abstract"><span class="toc-number">2.1.</span> <span class="toc-text">Abstract</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Introduction"><span class="toc-number">2.2.</span> <span class="toc-text">Introduction</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Background"><span class="toc-number">2.3.</span> <span class="toc-text">Background</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Shared-Memory"><span class="toc-number">2.4.</span> <span class="toc-text">Shared Memory</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#MOTIVATION-OF-THE-WORK"><span class="toc-number">3.</span> <span class="toc-text">MOTIVATION  OF THE WORK</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Principles-of-Hash-based-Accumulators"><span class="toc-number">3.1.</span> <span class="toc-text">Principles of Hash-based Accumulators</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Philosophy-of-HSMU-SpGEMM-Accumulator-Design"><span class="toc-number">3.2.</span> <span class="toc-text">Philosophy of HSMU-SpGEMM Accumulator Design</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#HSMU-SPGEMM"><span class="toc-number">4.</span> <span class="toc-text">HSMU-SPGEMM</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#HSMU-SpGEMM-Accumulator-Design"><span class="toc-number">4.1.</span> <span class="toc-text">HSMU-SpGEMM Accumulator Design</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Generate-the-Sorted-Ccol-Array"><span class="toc-number">4.2.</span> <span class="toc-text">Generate the Sorted Ccol Array</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/08/11/netty/" title="Netty">Netty</a><time datetime="2025-08-11T06:33:20.000Z" title="发表于 2025-08-11 14:33:20">2025-08-11</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/08/05/SpringCloud/" title="SpringCloud">SpringCloud</a><time datetime="2025-08-05T11:29:03.000Z" title="发表于 2025-08-05 19:29:03">2025-08-05</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/28/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E5%BC%80%E5%8F%91/" title="微信小程序开发">微信小程序开发</a><time datetime="2025-07-28T08:46:39.000Z" title="发表于 2025-07-28 16:46:39">2025-07-28</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/23/Nginx/" title="Nginx">Nginx</a><time datetime="2025-07-23T08:19:20.000Z" title="发表于 2025-07-23 16:19:20">2025-07-23</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/06/24/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/" title="设计模式">设计模式</a><time datetime="2025-06-24T05:53:00.000Z" title="发表于 2025-06-24 13:53:00">2025-06-24</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url(/image/bg.jpg);"><div id="footer-wrap"><div class="copyright">&copy;2025 By Explainfuture</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.3.5</a></div><div class="footer_custom_text">良辰美景奈何天。<p><a target="_blank" href="https://hexo.io/"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&logo=hexo" title="博客框架为Hexo"></a>&nbsp;<a target="_blank" href="https://butterfly.js.org/"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&logo=bitdefender" title="主题采用butterfly"></a>&nbsp;<a target="_blank" href="https://www.jsdelivr.com/"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/CDN-jsDelivr-orange?style=flat&logo=jsDelivr" title="本站使用JsDelivr为静态资源提供CDN加速"></a> &nbsp;<a target="_blank" href="https://vercel.com/ "><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Hosted-Vervel-brightgreen?style=flat&logo=Vercel" title="本站采用双线部署，默认线路托管于Vercel"></a>&nbsp;<a target="_blank" href="https://vercel.com/ "><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Hosted-Coding-0cedbe?style=flat&logo=Codio" title="本站采用双线部署，联通线路托管于Coding"></a>&nbsp;<a target="_blank" href="https://github.com/"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&logo=GitHub" title="本站项目由Gtihub托管"></a>&nbsp;<a target="_blank" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&logo=Claris" title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可"></a></p></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><div class="js-pjax"></div><script defer="defer" id="fluttering_ribbon" mobile="true" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-fluttering-ribbon.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/metingjs/dist/Meting.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="请输入关键字" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>